name: Evaluate Model
on:
  workflow_run:
    workflows: ["Tests"]
    types: [completed]

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: pip install -r requirements.txt torch scikit-learn

    - name: Calculate Real Metrics
  run: |
    python -c "
    import json
    from transformers import pipeline

    # 1. Chargez le modèle (chemin relatif depuis la racine du dépôt)
    classifier = pipeline('text-classification', 
                        model='./saved_models/',
                        tokenizer='bert-base-uncased')

    # 2. Testez avec des phrases réelles (à adapter)
    test_samples = [
        {'text': 'Ce film est excellent', 'expected': 'POSITIVE'},
        {'text': 'Je déteste ce produit', 'expected': 'NEGATIVE'}
    ]

    # 3. Calculez la précision
    correct = 0
    for sample in test_samples:
        pred = classifier(sample['text'])[0]['label']
        if pred == sample['expected']:
            correct += 1
    accuracy = correct / len(test_samples)

    # 4. Sauvegardez les résultats
    with open('metrics.json', 'w') as f:
        json.dump({'accuracy': accuracy, 'test_samples': len(test_samples)}, f)

    # 5. Échouez si < 85%
    assert accuracy >= 0.85, f'Précision trop faible: {accuracy:.2f}'
    "