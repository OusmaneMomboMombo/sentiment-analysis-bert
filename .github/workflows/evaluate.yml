name: Evaluate Model
on:
  workflow_run:
    workflows: ["Tests"]
    types: [completed]

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: pip install -r requirements.txt torch transformers

    - name: Run evaluation
      run: |
        python -c "
        import json
        from transformers import pipeline

        test_cases = [
            ('Super produit !', 'POSITIVE'),
            ('Très déçu par ce service', 'NEGATIVE'),
            ('Exactement ce que je cherchais', 'POSITIVE'),
            ('Qualité médiocre', 'NEGATIVE'),
            ('Rapport qualité-prix imbattable', 'POSITIVE')
        ]

        classifier = pipeline('text-classification', 
                            model='./saved_models/',
                            tokenizer='bert-base-uncased')

        correct = sum(
            1 for text, expected in test_cases
            if classifier(text)[0]['label'] == expected
        )
        accuracy = correct / len(test_cases)

        with open('metrics.json', 'w') as f:
            json.dump({'accuracy': accuracy}, f)
        
        assert accuracy >= 0.85, f'Accuracy {accuracy:.1%} < 85%'
        "

    - name: Upload results
      uses: actions/upload-artifact@v4  # Version mise à jour
      with:
        name: metrics
        path: metrics.json