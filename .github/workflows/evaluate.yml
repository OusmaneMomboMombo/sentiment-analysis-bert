name: Evaluate Model
on:
  workflow_run:
    workflows: ["Tests"]
    types: [completed]

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install transformers torch

    - name: Clean up model files
      run: |
        # Garde seulement les fichiers nécessaires
        cd saved_models
        rm -f model.safetensors bert_sentiment.pth
        ls -l  # Vérification

    - name: Run evaluation
      run: |
        python -c "
        import json
        import torch
        from transformers import AutoModelForSequenceClassification, AutoTokenizer

        # Configuration
        model_dir = './saved_models'
        test_cases = [
            ('Super produit !', 1),
            ('Très déçu', 0),
            ('Je recommande', 1),
            ('Mauvaise qualité', 0),
            ('Excellent rapport qualité-prix', 1)
        ]

        # Chargement avec désactivation explicite de safetensors
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        model = AutoModelForSequenceClassification.from_pretrained(
            model_dir,
            local_files_only=True,
            use_safetensors=False  # Force le format PyTorch
        )
        model.eval()

        # Évaluation
        correct = 0
        for text, expected in test_cases:
            inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
            with torch.no_grad():
                outputs = model(**inputs)
            predicted = torch.argmax(outputs.logits).item()
            correct += (predicted == expected)

        # Résultats
        accuracy = correct / len(test_cases)
        print(f'Accuracy: {accuracy:.1%}')
        
        with open('metrics.json', 'w') as f:
            json.dump({
                'accuracy': accuracy,
                'tested_samples': len(test_cases),
                'model_format': 'pytorch'
            }, f)
        
        assert accuracy >= 0.85, f'Accuracy {accuracy:.1%} < 85%'
        "

    - name: Upload metrics
      uses: actions/upload-artifact@v4
      with:
        name: model-metrics
        path: metrics.json
        