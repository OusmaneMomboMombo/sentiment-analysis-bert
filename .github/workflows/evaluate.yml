name: Evaluate Model
on:
  workflow_run:
    workflows: ["Tests"]
    types: [completed]

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: pip install -r requirements.txt torch scikit-learn

    - name: Run minimal check
      run: |
        python -c "
        from transformers import AutoModelForSequenceClassification, AutoTokenizer
        import torch
        
        # 1. Chargez un modèle BERT vierge
        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
        
        # 2. Test basique (sans votre modèle personnalisé)
        tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
        inputs = tokenizer('Ce film est bon', return_tensors='pt')
        
        # 3. Vérifiez que l'inférence fonctionne
        try:
            with torch.no_grad():
                outputs = model(**inputs)
            print('✅ Test d\'inférence réussi')
        except Exception as e:
            raise Exception(f'Échec du test : {str(e)}')
        "